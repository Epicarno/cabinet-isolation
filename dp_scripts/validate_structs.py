#!/usr/bin/env python3
"""
validate_structs.py ‚Äî –í–∞–ª–∏–¥–∞—Ü–∏—è DPT-–∫–ª–∞—Å—Å–æ–≤: CSV struct ‚Üî DPL DpType.

–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç struct-–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ CSV-—Ñ–∞–π–ª–æ–≤ –º–Ω–µ–º–æ—Å—Ö–µ–º (–∫–æ–ª–æ–Ω–∫–∞ 5)
—Å DpType-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏ –∏–∑ DPL-—Ñ–∞–π–ª–æ–≤ –≤ DPLs/<–®–ö–ê–§>/.

–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π:
  ERROR   ‚Äî struct –≤ CSV, –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ—Ç –≤ DPL (–≤–µ—Ä–æ—è—Ç–Ω–∞—è –æ—à–∏–±–∫–∞)
  WARN    ‚Äî _Static-–≤–∞—Ä–∏–∞–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ DPL-—Ç–∏–ø–∞ (–±–µ–∑ DPT-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
  INFO    ‚Äî —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∫–ª–∞—Å—Å (SCADTECH, DI_scadtech –∏ —Ç.–ø.) ‚Äî –æ—Å—Ç–∞–≤–ª–µ–Ω
  UNUSED  ‚Äî DPL-—Ç–∏–ø –±–µ–∑ —Å—Å—ã–ª–æ–∫ –≤ CSV (–º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏—à–Ω–∏–º –≤ DPL)

–í—ã—Ö–æ–¥ (reports/datapoints/):
  _validate_structs.txt  ‚Äî –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç
  _struct_errors.txt     ‚Äî —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python validate_structs.py                  # –≤—Å–µ —à–∫–∞—Ñ—ã –∏–∑ cabinets.txt
  python validate_structs.py SHD_03_1         # –æ–¥–∏–Ω —à–∫–∞—Ñ
"""

from __future__ import annotations

import argparse
import re
import sys
from pathlib import Path

# Windows cp1251 –ª–æ–º–∞–µ—Ç Unicode-—Å–∏–º–≤–æ–ª—ã ‚Üí —Ñ–æ—Ä—Å–∏—Ä—É–µ–º UTF-8
sys.stdout.reconfigure(encoding='utf-8', errors='replace')
sys.stderr.reconfigure(encoding='utf-8', errors='replace')
from collections import defaultdict

# ---------------------------------------------------------------------------
SCRIPT_DIR  = Path(__file__).resolve().parent
SCRIPTS_DIR = SCRIPT_DIR.parent          # scripts/
MODULES_DIR = SCRIPTS_DIR.parent          # Modules/
MNEMO_DIR   = MODULES_DIR / "ventcontent" / "panels" / "vision" / "LCSMnemo"
DPL_DIR     = MODULES_DIR / "DPLs"
REPORT_DIR  = MODULES_DIR / "reports" / "datapoints"

# –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–ª–∞—Å—Å—ã ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º, –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ INFO
KNOWN_SPECIFIC = {
    "SCADTECH_DI_SHUOD",
    "DI_scadtech",
    "DI_scadtech_PNR",
    "SCADTECH_DI",
    "SCADTECH_AI",
    "TAIRA_1_DI_VENT",
}

# –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: CSV struct ‚Üí –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è DPL
KNOWN_RENAMES = {
    "PUMP_ETRA": "ETRA_PUMP",
}


def parse_dpl_types(dpl_path: Path) -> set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ DpType –∏–∑ DPL-—Ñ–∞–π–ª–∞.

    –§–æ—Ä–º–∞—Ç —Å–µ–∫—Ü–∏–∏ # DpType:
      TypeName                          ‚Üê –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
      TAIRA_PUMP.TAIRA_PUMP\t1#1        ‚Üê –∫–æ—Ä–Ω–µ–≤–æ–π —Ç–∏–ø (–±–µ—Ä—ë–º —á–∞—Å—Ç—å –¥–æ —Ç–æ—á–∫–∏)
      \tState\t21#2                     ‚Üê –≤–ª–æ–∂–µ–Ω–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
      \tname\t25#4
      TAIRA_AI.TAIRA_AI\t1#1            ‚Üê —Å–ª–µ–¥—É—é—â–∏–π —Ç–∏–ø
    """
    types: set[str] = set()
    in_dptype_section = False

    try:
        text = dpl_path.read_text(encoding="utf-8", errors="replace")
    except Exception:
        return types

    for line in text.splitlines():
        stripped = line.strip()

        if stripped == "# DpType":
            in_dptype_section = True
            continue
        if stripped.startswith("# ") and in_dptype_section:
            if stripped != "# DpType":
                in_dptype_section = False
                continue

        if not in_dptype_section or not stripped:
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å tab)
        if line.startswith("\t"):
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ "TypeName"
        if stripped == "TypeName":
            continue

        # –ö–æ—Ä–Ω–µ–≤–æ–π DpType: "TAIRA_PUMP.TAIRA_PUMP\t1#1"
        # –§–æ—Ä–º–∞—Ç: DPT_NAME.DPT_NAME\t<type_id>#<element_id>
        parts = stripped.split("\t")
        if len(parts) >= 2 and "." in parts[0]:
            type_name = parts[0].split(".")[0]
            types.add(type_name)

    return types


def parse_dpl_instances(dpl_path: Path) -> dict[str, str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç DP-–∏–Ω—Å—Ç–∞–Ω—Å—ã –∏–∑ DPL-—Ñ–∞–π–ª–∞.

    –§–æ—Ä–º–∞—Ç —Å–µ–∫—Ü–∏–∏ # Datapoint/DpId:
      dpName\t\tID  (dpName ‚Äî –∏–º—è —Ç–æ—á–∫–∏, ID ‚Äî —á–∏—Å–ª–æ–≤–æ–π)

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: dpName ‚Üí dpType (–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞).
    """
    instances: dict[str, str] = {}
    in_dp_section = False
    current_type = ""

    try:
        text = dpl_path.read_text(encoding="utf-8", errors="replace")
    except Exception:
        return instances

    for line in text.splitlines():
        stripped = line.strip()

        if stripped == "# Datapoint/DpId":
            in_dp_section = True
            continue
        if stripped.startswith("# ") and in_dp_section:
            if stripped != "# Datapoint/DpId":
                in_dp_section = False
                continue

        if not in_dp_section:
            continue

        if not stripped:
            continue

        parts = stripped.split("\t")

        # –°—Ç—Ä–æ–∫–∞ —Ç–∏–ø–∞: "TypeName\tTypeId"
        if len(parts) == 2 and parts[1].isdigit():
            current_type = parts[0]
            continue

        # –°—Ç—Ä–æ–∫–∞ –∏–Ω—Å—Ç–∞–Ω—Å–∞: "dpName\t\tDPID" (–≤—Ç–æ—Ä–æ–µ –ø–æ–ª–µ –ø—É—Å—Ç–æ–µ)
        if len(parts) >= 3 and parts[1] == "" and current_type:
            dp_name = parts[0]
            if dp_name and not dp_name.startswith("_"):
                instances[dp_name] = current_type

    return instances


def load_csv_structs(mnemo_dir: Path,
                     cabinet: str) -> dict[str, list[tuple[str, str]]]:
    """–°–æ–±–∏—Ä–∞–µ—Ç struct-–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ CSV: struct ‚Üí [(refName, csv_file), ...].

    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ —à–∫–∞—Ñ—É.
    """
    structs: dict[str, list[tuple[str, str]]] = defaultdict(list)

    cab_dir = mnemo_dir / cabinet
    if not cab_dir.is_dir():
        return structs

    for csv_file in sorted(cab_dir.glob("*.csv")):
        try:
            text = csv_file.read_text(encoding="utf-8", errors="replace")
        except Exception:
            continue

        for line in text.strip().split("\n")[1:]:  # skip header
            parts = line.split(",")
            if len(parts) < 5:
                continue

            ref_name = parts[0].strip()
            dp_name  = parts[1].strip()
            struct   = parts[4].strip()

            if not struct:
                continue

            # –¢–æ—á–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å —à–∫–∞—Ñ—É
            ref_ok = ref_name.startswith(cabinet)
            dp_ok  = dp_name.startswith(cabinet)
            if not ref_ok and not dp_ok:
                continue

            key = dp_name if dp_name else ref_name
            structs[struct].append((key, csv_file.name))

    return structs


def classify_mismatch(struct: str, dpl_types: set[str]) -> tuple[str, str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –¥–ª—è struct –±–µ–∑ DPL-—Ç–∏–ø–∞.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –ø–æ—è—Å–Ω–µ–Ω–∏–µ).
    """
    # –ò–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
    if struct in KNOWN_RENAMES:
        correct = KNOWN_RENAMES[struct]
        return ("ERROR", f"–ø–µ—Ä–µ–≤—ë—Ä–Ω—É—Ç–æ–µ –∏–º—è ‚Üí –ø—Ä–∞–≤–∏–ª—å–Ω–æ: {correct}")

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∫–ª–∞—Å—Å ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    if struct in KNOWN_SPECIFIC:
        return ("INFO", "—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∫–ª–∞—Å—Å ‚Äî –æ—Å—Ç–∞–≤–ª–µ–Ω")

    # –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞
    for prefix in ("SCADTECH_", "DI_scadtech"):
        if struct.startswith(prefix):
            return ("INFO", "—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∫–ª–∞—Å—Å ‚Äî –æ—Å—Ç–∞–≤–ª–µ–Ω")

    # _Static ‚Äî —Å—É—Ñ—Ñ–∏–∫—Å, –±–∞–∑–æ–≤—ã–π —Ç–∏–ø –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ DPL
    if struct.endswith("_Static"):
        base = struct.replace("_Static", "")
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º VZZDR ‚Üí VZZD
        base_norm = base.replace("VZZDR", "VZZD")
        if base in dpl_types or base_norm in dpl_types:
            return ("WARN", f"Static-–≤–∞—Ä–∏–∞–Ω—Ç —Ç–∏–ø–∞ {base_norm} (DPT –±–µ–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)")
        return ("WARN", f"Static-–≤–∞—Ä–∏–∞–Ω—Ç, –±–∞–∑–æ–≤—ã–π —Ç–∏–ø {base} —Ç–æ–∂–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ DPL")

    # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø
    return ("ERROR", "struct –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ DPL")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="–í–∞–ª–∏–¥–∞—Ü–∏—è DPT-–∫–ª–∞—Å—Å–æ–≤: CSV struct ‚Üî DPL DpType"
    )
    parser.add_argument(
        "cabinets", nargs="*",
        help="–®–∫–∞—Ñ—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –∏–∑ cabinets.txt)"
    )
    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∫–∞—Ñ—ã
    if args.cabinets:
        cabinets = args.cabinets
    else:
        cabinets_file = SCRIPTS_DIR / "cabinets.txt"
        if cabinets_file.exists():
            cabinets = [
                line.strip()
                for line in cabinets_file.read_text(encoding="utf-8").splitlines()
                if line.strip() and not line.strip().startswith("#")
            ]
        else:
            # –í—Å–µ –ø–∞–ø–∫–∏ –≤ DPLs/
            if DPL_DIR.exists():
                cabinets = sorted(d.name for d in DPL_DIR.iterdir() if d.is_dir())
            else:
                print(f"–û–®–ò–ë–ö–ê: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ {DPL_DIR}", file=sys.stderr)
                sys.exit(1)

    if not cabinets:
        print("–ù–µ—Ç —à–∫–∞—Ñ–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", file=sys.stderr)
        sys.exit(1)

    REPORT_DIR.mkdir(parents=True, exist_ok=True)

    all_report_lines: list[str] = []
    all_errors: list[str] = []
    total_ok = 0
    total_warn = 0
    total_error = 0
    total_info = 0
    total_unused = 0

    for cabinet in cabinets:
        print(f"\n{'='*60}")
        print(f"–®–∫–∞—Ñ: {cabinet}")
        print(f"{'='*60}")

        # 1. –°–æ–±–∏—Ä–∞–µ–º DPT-—Ç–∏–ø—ã –∏–∑ DPL
        dpl_cab_dir = DPL_DIR / cabinet
        dpl_types: set[str] = set()
        if dpl_cab_dir.is_dir():
            for dpl_file in sorted(dpl_cab_dir.glob("*.dpl")):
                types = parse_dpl_types(dpl_file)
                dpl_types.update(types)
                print(f"  DPL: {dpl_file.name} ‚Üí {len(types)} —Ç–∏–ø–æ–≤")
        else:
            print(f"  ‚ö† DPL-–ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {dpl_cab_dir}")

        # 2. –°–æ–±–∏—Ä–∞–µ–º struct-–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ CSV
        csv_structs = load_csv_structs(MNEMO_DIR, cabinet)
        print(f"  CSV: {len(csv_structs)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö struct-–∑–Ω–∞—á–µ–Ω–∏–π")

        if not csv_structs:
            print("  –ù–µ—Ç CSV-–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            continue

        # 3. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º
        ok_structs: list[str] = []
        issues: list[tuple[str, str, str, int]] = []  # (struct, cat, msg, count)

        for struct in sorted(csv_structs.keys()):
            count = len(csv_structs[struct])
            if struct in dpl_types:
                ok_structs.append(struct)
                total_ok += count
            else:
                cat, msg = classify_mismatch(struct, dpl_types)
                issues.append((struct, cat, msg, count))
                if cat == "ERROR":
                    total_error += count
                elif cat == "WARN":
                    total_warn += count
                else:
                    total_info += count

        # DPL-—Ç–∏–ø—ã –±–µ–∑ —Å—Å—ã–ª–æ–∫ –≤ CSV
        csv_struct_names = set(csv_structs.keys())
        unused_types = sorted(dpl_types - csv_struct_names)
        total_unused += len(unused_types)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
        section = []
        section.append(f"\n{'='*60}")
        section.append(f"–®–ö–ê–§: {cabinet}")
        section.append(f"  DPL-—Ç–∏–ø–æ–≤: {len(dpl_types)}   CSV struct: {len(csv_structs)}")
        section.append(f"{'='*60}")

        if ok_structs:
            section.append(f"\n‚úÖ –°–û–í–ü–ê–î–ê–Æ–¢ ({len(ok_structs)} —Ç–∏–ø–æ–≤):")
            for s in ok_structs:
                cnt = len(csv_structs[s])
                section.append(f"  {s:<35s} {cnt:>5d} —Ç–æ—á–µ–∫")

        if issues:
            section.append(f"\n‚ö† –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø ({len(issues)} —Ç–∏–ø–æ–≤):")
            for struct, cat, msg, count in issues:
                section.append(f"  [{cat:5s}] {struct:<35s} {count:>5d} —Ç–æ—á–µ–∫ ‚Äî {msg}")

                # –î–ª—è –æ—à–∏–±–æ–∫ ‚Äî –¥–µ—Ç–∞–ª–∏ –ø–æ CSV-—Ñ–∞–π–ª–∞–º
                if cat == "ERROR":
                    files = set(f for _, f in csv_structs[struct])
                    err_line = f"  {cabinet}: {struct} ({count} —Ç–æ—á–µ–∫) ‚Äî {msg}"
                    err_line += f"  [CSV: {', '.join(sorted(files))}]"
                    all_errors.append(err_line)

        if unused_types:
            section.append(f"\nüîá DPL-–¢–ò–ü–´ –ë–ï–ó CSV ({len(unused_types)}):")
            for t in unused_types:
                section.append(f"  {t}")

        all_report_lines.extend(section)

        # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
        for line in section:
            print(line)

    # –°–≤–æ–¥–∫–∞
    summary = []
    summary.append(f"\n{'='*60}")
    summary.append(f"–ò–¢–û–ì–û")
    summary.append(f"{'='*60}")
    summary.append(f"  ‚úÖ OK:        {total_ok:>6d} —Ç–æ—á–µ–∫ (struct —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å DPL)")
    summary.append(f"  ‚ö†  WARN:      {total_warn:>6d} —Ç–æ—á–µ–∫ (_Static –±–µ–∑ DPT)")
    summary.append(f"  ‚ùå ERROR:     {total_error:>6d} —Ç–æ—á–µ–∫ (struct ‚â† DPL)")
    summary.append(f"  ‚Ñπ  INFO:      {total_info:>6d} —Ç–æ—á–µ–∫ (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª–µ–Ω—ã)")
    summary.append(f"  üîá UNUSED:    {total_unused:>6d} DPL-—Ç–∏–ø–æ–≤ –±–µ–∑ CSV")

    all_report_lines.extend(summary)
    for line in summary:
        print(line)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ç—á—ë—Ç—ã
    report_file = REPORT_DIR / "_validate_structs.txt"
    report_file.write_text("\n".join(all_report_lines), encoding="utf-8")
    print(f"\n–û—Ç—á—ë—Ç: {report_file}")

    if all_errors:
        errors_file = REPORT_DIR / "_struct_errors.txt"
        header = [
            f"# –û—à–∏–±–∫–∏ struct: CSV ‚â† DPL ‚Äî {len(all_errors)} –∑–∞–ø–∏—Å–µ–π",
            f"# –≠—Ç–∏ struct-–∑–Ω–∞—á–µ–Ω–∏—è –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤ CSV-—Ñ–∞–π–ª–∞—Ö\n",
        ]
        errors_file.write_text(
            "\n".join(header + all_errors), encoding="utf-8"
        )
        print(f"–û—à–∏–±–∫–∏: {errors_file}")
    else:
        print("–û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!")


if __name__ == "__main__":
    main()
